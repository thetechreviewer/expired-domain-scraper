{
  "title": "Expired Domain Link Finder",
  "type": "object",
  "schemaVersion": 1,
  "properties": {
    "startUrls": {
      "title": "Start URLs (one or more)",
      "type": "array",
      "description": "One or more root domains/URLs to crawl. Example: https://example.com or example.com",
      "editor": "stringList",
      "items": {
        "type": "string"
      },
      "prefill": [
        "https://example.com"
      ]
    },
    "startUrl": {
      "title": "Single start URL (legacy)",
      "type": "string",
      "description": "Optional backward-compatible single URL input.",
      "editor": "textfield"
    },
    "maxPages": {
      "title": "Max pages to crawl (per start URL)",
      "type": "integer",
      "description": "Set 0 to crawl all discovered in-domain pages for each start URL.",
      "minimum": 0,
      "default": 200
    },
    "maxCrawlDepth": {
      "title": "Max click depth",
      "type": "integer",
      "description": "0 = unlimited depth. 1 = only links from the start page. 2+ = deeper crawl.",
      "minimum": 0,
      "default": 0
    },
    "followSubdomains": {
      "title": "Include subdomains",
      "type": "boolean",
      "description": "If true, crawling includes subdomains of the target domain.",
      "default": true
    },
    "maxConcurrency": {
      "title": "Max crawler concurrency",
      "type": "integer",
      "description": "Higher values are faster but heavier on resources.",
      "minimum": 1,
      "maximum": 200,
      "default": 20
    },
    "requestTimeoutSecs": {
      "title": "Crawler request timeout (seconds)",
      "type": "integer",
      "description": "How long to wait for each page request before timing out.",
      "minimum": 5,
      "maximum": 120,
      "default": 30
    },
    "includeNofollow": {
      "title": "Include nofollow links",
      "type": "boolean",
      "description": "If true, links marked with rel=nofollow will also be checked.",
      "default": true
    },
    "checkDomainExpiry": {
      "title": "Try to detect likely expired target domains",
      "type": "boolean",
      "description": "Adds DNS/root checks for each broken link domain.",
      "default": true
    },
    "checkTimeoutSecs": {
      "title": "Outgoing link check timeout (seconds)",
      "type": "integer",
      "description": "How long to wait when checking each outgoing link before timing out.",
      "minimum": 3,
      "maximum": 120,
      "default": 20
    },
    "linkCheckConcurrency": {
      "title": "Outgoing link check concurrency",
      "type": "integer",
      "description": "Number of outgoing links to check simultaneously.",
      "minimum": 1,
      "maximum": 200,
      "default": 30
    },
    "useApifyProxy": {
      "title": "Use Apify Proxy",
      "type": "boolean",
      "description": "Enable Apify Proxy for crawling and outgoing link checks.",
      "default": false
    },
    "useResidentialProxies": {
      "title": "Use residential proxies (Apify add-on)",
      "type": "boolean",
      "description": "If enabled, actor requests proxy group RESIDENTIAL. Charges depend on your Apify plan.",
      "default": false
    },
    "apifyProxyGroups": {
      "title": "Additional Apify Proxy groups",
      "type": "array",
      "description": "Optional extra groups such as SHADER, BUYPROXIES94952, etc.",
      "editor": "stringList",
      "items": {
        "type": "string"
      }
    },
    "apifyProxyCountry": {
      "title": "Apify Proxy country code",
      "type": "string",
      "description": "Optional 2-letter country code (e.g. US).",
      "editor": "textfield",
      "sectionCaption": "Proxy settings"
    },
    "maxRequestsPerMinute": {
      "title": "Max requests per minute",
      "type": "integer",
      "description": "Limits how many pages the crawler requests per minute. Lower values reduce the chance of getting blocked. 0 = unlimited.",
      "minimum": 0,
      "maximum": 1000,
      "default": 60,
      "sectionCaption": "Rate limiting"
    },
    "requestDelayMin": {
      "title": "Min delay between requests (ms)",
      "type": "integer",
      "description": "Minimum random delay in milliseconds before each request. Combined with max delay to create natural-looking request patterns.",
      "minimum": 0,
      "maximum": 60000,
      "default": 500
    },
    "requestDelayMax": {
      "title": "Max delay between requests (ms)",
      "type": "integer",
      "description": "Maximum random delay in milliseconds before each request. A random value between min and max delay is chosen for each request.",
      "minimum": 0,
      "maximum": 60000,
      "default": 3000
    },
    "respectRobotsTxt": {
      "title": "Respect robots.txt",
      "type": "boolean",
      "description": "If true, the crawler will honor robots.txt rules and skip disallowed pages.",
      "default": true
    },
    "excludeDomains": {
      "title": "Exclude domains from checking",
      "type": "array",
      "description": "List of domains to skip when checking outgoing links. Useful for skipping known large sites like google.com, facebook.com, etc.",
      "editor": "stringList",
      "items": {
        "type": "string"
      },
      "prefill": [
        "google.com",
        "facebook.com",
        "twitter.com",
        "youtube.com",
        "linkedin.com",
        "instagram.com",
        "amazon.com",
        "wikipedia.org"
      ],
      "sectionCaption": "Filtering"
    },
    "minBrokenLinksPerDomain": {
      "title": "Min broken links to flag a domain",
      "type": "integer",
      "description": "Only flag a domain as a candidate if it has at least this many broken links. Reduces noise from one-off 404s.",
      "minimum": 1,
      "default": 1
    },
    "extractAnchorText": {
      "title": "Extract anchor text",
      "type": "boolean",
      "description": "If true, captures the visible link text for each broken outgoing link. Useful for understanding context and SEO value.",
      "default": true
    }
  },
  "required": []
}
